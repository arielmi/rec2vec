{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "stemming the techs.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hGV2nPaa26U",
        "colab_type": "text"
      },
      "source": [
        "## stemming the techs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_S87ghTJv9z4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_techs = pd.read_csv(\"https://raw.githubusercontent.com/arielmi/recipe2vec/master/raw_techs.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHS5wzwRFBvK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = corpus.str.lower()\n",
        "corpus = corpus.apply(lambda sentence: RegexpTokenizer(r'\\w+').tokenize(sentence))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr5BVnNcFEtW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to apply each sentence in the corpus\n",
        "# tokenized_sentence is a list\n",
        "# techs is a series of stemmed cook-techniques\n",
        "def stem_techs(tokenized_sentence, techs):\n",
        "  ps = PorterStemmer()\n",
        "  output_sentence = copy.deepcopy(tokenized_sentence)\n",
        "  words_that_stemmed = []\n",
        "  for i, word in enumerate(tokenized_sentence):\n",
        "    stemmed = ps.stem(word)\n",
        "    if (techs == stemmed).any():\n",
        "      output_sentence[i] = stemmed\n",
        "      words_that_stemmed.append(stemmed)\n",
        "  return pd.Series([output_sentence, words_that_stemmed])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEBzAfiVoxuD",
        "colab_type": "text"
      },
      "source": [
        "Cell to apply desired stemmings, approx 15 min"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqzeshdhIab-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# raw_techs['stemmed'] is the stemmed series of raw_techs\n",
        "df_after_stem = corpus.apply(lambda sentence: stem_techs(sentence,raw_techs['stemmed']))\n",
        "df_after_stem.columns = ['sentence', 'stemmed']\n",
        "df_after_stem['sentence'] = df_after_stem['sentence'].apply(lambda x: \" \".join(x))\n",
        "stemmed_counts = pd.Series(list(chain.from_iterable(df_after_stem[\"stemmed\"].tolist()))).value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}