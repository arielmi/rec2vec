# -*- coding: utf-8 -*-
"""create_corpus.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1t6o5MB63ADVUsmUjVhbL9cQdYEDjbd_E
"""

import numpy as np
import pandas as pd
import copy
# import scipy.stats as st
from sklearn.manifold import TSNE
# import seaborn as sns
import matplotlib.pyplot as plt
from gensim.models import Word2Vec
import re
from nltk.stem import PorterStemmer
import os
import json
# import nltk
# nltk.download('punkt')
from nltk import word_tokenize
from nltk.tokenize import RegexpTokenizer

with open("/content/drive/My Drive/Final Project/full_format_recipes.json", "r") as read_file:
    data = json.load(read_file)

df = pd.read_json("/content/drive/My Drive/Final Project/full_format_recipes.json")

directions = df.directions.dropna()

# unpack the lists
from itertools import chain
my_object = list(chain.from_iterable(directions.tolist()))
# unpack to a long str
as_one_str = ''.join(my_object)
# split the string to sentences according to a "." that comes after a word
lst_of_sentences = re.split("((?<=[A-Za-z])+\.)", as_one_str)
# store the sentences in a Pandas Series
corpus = pd.Series(lst_of_sentences)
corpus = corpus[corpus!="."]